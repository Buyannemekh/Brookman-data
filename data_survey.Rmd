---
title: "broockman_kalla"
author: "Buyannemekh Munkhbat"
date: "10/25/2018"
output:
  html_document: default
  pdf_document: default
---

```{r, include=FALSE}
rm(list = ls())
library(foreign)
library(pander)
library(plyr)
library(sandwich)
library(lmtest)
library(data.table)
library(ggplot2)
library(reshape2)
library(glmnet)
library(memoutils)
library(dplyr)
library(purrr)


library(devtools)
library(tidyverse)
library(rprojroot)

library(kableExtra)
library(knitr)
library(tibble)
library(magrittr)
library(aod)
library(broom)
library(grid)
library(gridExtra)

library(ggpubr)
library(ggplot2)
wd <- '' # enter your working directory here
set.seed(5953921)

data <- read.dta(paste0(wd, 'broockman_kalla_replication_data.dta'))
# Note: Variables that begin with vf_ come from the voter file.
# Variables that end with _t0 were collected on the baseline survey.
```


### Items Capturing Primary Outcomes Appearing on All Surveys

The below items appeared on multiple surveys; the # sign below will be replaced with the survey number in our analysis:

* The baseline survey is survey 0;
* the 3-day survey is survey 1;
* the 3-week survey is survey 2;
* the 6-week survey is survey 3, and;
* the 3-month survey is survey 4.

Item names appear in bold next to each item. For the remainder of the paper we will refer to these items by these bolded names.

* **miami_trans_law_t#**: Miami-Dade county recently passed a law that prohibits discrimination in housing, employment and public accommodations based on gender identity and expression, a category that includes transgender men and women [for **miami_trans_law_withdef_t#**, adds the phrase here, "(people who were designated one gender at birth, but now identify as a different gender)."]. Do you favor or oppose this new law?
* **miami_trans_law2_t#**: Some people say it's important to protect transgender people from discrimination in housing and employment. Other people have concerns about society becoming too accepting of transgender people, and do not want transgender people included in our non-discrimination law. What do you think? Do you agree or disagree that Miami law should protect transgender people [for **miami_trans_law2_withdef_t#**, adds the phrase here, "(people who were designated one gender at birth, but now identify as a different gender)."] from discrimination?
* **trans_law_post_ad_t3**: On the third survey only, we asked about the law again after showing an opposition video: "We've mentioned that Miami-Dade county recently passed a law that prohibits discrimination in housing, employment and public accommodations based on gender identity and expression, a category that includes transgender men and women (people who were designated one gender at birth, but now identify as a different gender). After seeing the video, do you favor or oppose this new law?" This item does not appear in any of the scales.
* **therm_trans_t#**: Feeling thermometer towards trans people (0-100) (From *(39)*)
* **gender_norm_abnormal_t#**: A man who identifies as a woman is psychologically abnormal (Modification from (*40, 41*)).
* **gender_norm_moral_t#**: It is morally wrong for a man to present himself as a woman in public (Modification from (*40*)).
* **gender_norm_trans_moral_wrong_t#**: Saying you are a gender that is different than the one you were born with is morally wrong (Modification from (*40, 41*)).
* **gender_norm_sexchange_t#**: I would support a friend choosing to have a sex change (Modification from (*42*)).

Starting with the second post-treatment survey, we also asked the below two items.  These items were composed and added after examining the results from the first post-treatment survey. An amended pre-analysis plan was submitted to EGAP to reflect the addition of these two questions.

* **trans_teacher_t#**: Transgender women (people who identify as women but were designated male at birth) should be allowed to serve as public school teachers.
* **trans_bathroom_t#**: It would be wrong to allow a transgender woman (a person who identifies as a woman but was designated male at birth) to use the womanâ€™s restroom (Modification from (*40*)).

### Outcome Indices

In our pre-analysis plan, we specified that we would combine multiple items into indices to test hypotheses. Combining outcomes into an index increases precision by decreasing survey measurement error and limits the potential for multiple hypothesis testing (*33*).

The indicies, to be described momentarily, are as follows:

* **all.dvs.t#**: An index of all primary outcomes, created to test the omnibus hypothesis that the treatment had any effects.
* **trans.tolerance.dv.t#**: An index of outcomes from all.dvs.t# capturing acceptance and tolerance towards -- instead of prejudice and stigma towards -- transgender people; this is all primary outcomes except for the two items about the law.
* **miami_trans_law_t#_avg**: An index of the two items about Miami's law protecting transgender people from discrimination in housing, employment, and public accomodations. Because these items were Likert scales with the same number of points and there were only two of them, the index is a simple average of the two items.
* **gender_nonconformity_t#**: Distinct from measuring transgender tolerance, we also constructed a scale capturing gender norms. As stated in our pre-analysis plan, effects on this measure represented a secondary hypothesis and this index is not a primary outcome of interest. (However, there do appear to be effects on this measure as well, but we do not discuss these in the main text due to space constraints.)

#### Pre-Specified Index of All Primary Outcomes

In the pre-analysis plan we indicated that the main hypothesis test will be whether an index of all primary outcomes shows statistical significance. We list these outcomes for each survey below. (In the pre-analysis plan we called this "main.dv.")

Note that we code the scale such that larger, more positive values indicate more tolerance and less prejudice.

```{r}
all.dv.names.t1 <- c('miami_trans_law_t1', 'miami_trans_law2_t1', 'therm_trans_t1',
                      'gender_norm_sexchange_t1', 'gender_norm_moral_t1',
                      'gender_norm_abnormal_t1', 'gender_norm_trans_moral_wrong_t1')
```

#### Transgender Tolerance Index

```{r}
trans.tolerance.dvs.t0 <- c('therm_trans_t0', 'gender_norms_sexchange_t0',
                            'gender_norms_moral_t0', 'gender_norms_abnormal_t0')

trans.tolerance.dvs.t1 <- c('therm_trans_t1', 'gender_norm_sexchange_t1',
                            'gender_norm_moral_t1', 'gender_norm_abnormal_t1',
                            'gender_norm_trans_moral_wrong_t1')
```

#### Law Items Index
```{r}
trans.law.dvs.t0 <- c('miami_trans_law_t0', 'miami_trans_law2_t0')
trans.law.dvs.t1 <- c('miami_trans_law_t1', 'miami_trans_law2_t1')
```


#### Secondary Outcome: Gender Non-Conformity Index
```{r}
gender.nonconformity.t0 <- c('gender_norm_looks_t0', 'gender_norm_rights_t0')
gender.nonconformity.t1 <- c('gender_norm_looks_t1', 'gender_norm_rights_t1')
```

### Reverse Coded Items
```{r, include = FALSE}
reverse.coded.items <- c('gender_norms_moral_t0', 'gender_norm_moral_t1',
                         'gender_norm_moral_t2', 'gender_norm_moral_t3',
                         'gender_norm_moral_t4', 'gender_norms_abnormal_t0',
                         'gender_norm_abnormal_t1', 'gender_norm_abnormal_t2',
                         'gender_norm_abnormal_t3','gender_norm_abnormal_t4',
                         'gender_norm_trans_moral_wrong_t1', 
                         'gender_norm_trans_moral_wrong_t2',
                         'gender_norm_trans_moral_wrong_t3',
                         'gender_norm_trans_moral_wrong_t4',
                         'trans_bathroom_t2', 'trans_bathroom_t3',
                         'trans_bathroom_t4', 'gender_norm_looks_t0',
                         'gender_norm_looks_t1', 'gender_norm_looks_t2',
                         'gender_norm_looks_t3', 'gender_norm_looks_t4',
                         'gender_norm_rights_t0', 'gender_norm_rights_t1',
                         'gender_norm_rights_t2', 'gender_norm_rights_t3',
                         'gender_norm_rights_t4', 'gender_norm_dress_t2',
                         'gender_norm_dress_t3', 'gender_norm_dress_t4')
for(item in reverse.coded.items) data[,item] <- -1 * data[,item]
```

### Procedue for Combining Outcomes into Indices

```{r, include = FALSE}
# Compute factor analysis outcome
compute.factor.dv <- function(dv.names, respondent.booleans, print.loadings = TRUE){
  responders <- data[respondent.booleans,]
  
  # Factor analysis
  factor.obj <- princomp(responders[, dv.names], cor=TRUE)
  if(print.loadings) print(loadings(factor.obj))
  dv <- as.vector(factor.obj$scores[,1])
  
  # More positive values on the factor should indicate more tolerance; reverse otherwise.
  if(cor(dv, responders$miami_trans_law_t0, use="complete.obs") < 0) dv <- -1 * dv
  
  # Put in the order of the main data frame
  dv.in.order <- dv[match(data$id, responders$id)]
  
  # Rescale to mean 0 sd 1 in placebo group; treatment effects can then be interpreted
  # as the effect in standard deviations the treatment would have among an untreated
  # population.
  dv.in.order <- (dv.in.order - mean(dv.in.order[!data$treat_ind], na.rm=TRUE)) /
    sd(dv.in.order[!data$treat_ind], na.rm=TRUE)
  
  return(as.vector(dv.in.order))
}
```

```{r, include = FALSE}
# In this code section we implement the procedures describe previously.

# First, misc. housekeeping.
# Recode age for small number of observations where it is missing.
data$vf_age[which(is.na(data$vf_age))] <- mean(data$vf_age, na.rm=TRUE)

# Language of interview
data$survey_language_es[is.na(data$survey_language_es)] <-
    data$survey_language_t0[is.na(data$survey_language_es)] == "ES"
data$survey_language_es[is.na(data$survey_language_es)] <- mean(data$survey_language_es, na.rm = TRUE)

# We subset to only those who came to door. contacted = came to door.
full.data <- data
data <- subset(data, contacted == 1)

# Compute the DVs in line with the above procedures.

# Omnibus DV of all primary outcomes.
data$all.dvs.t1 <- compute.factor.dv(all.dv.names.t1, data$respondent_t1==1 & !is.na(data$respondent_t1))


# Trans tolerance DV.
data$trans.tolerance.dv.t0 <- compute.factor.dv(trans.tolerance.dvs.t0, data$respondent_t0==1 & !is.na(data$respondent_t0))
data$trans.tolerance.dv.t1 <- compute.factor.dv(trans.tolerance.dvs.t1, data$respondent_t1==1 & !is.na(data$respondent_t1))


# Law DV.
# Create outcome scale by averaging over the two questions.
data$miami_trans_law_t0_avg <- (data$miami_trans_law_t0 + data$miami_trans_law2_t0)/2
data$miami_trans_law_t1_avg <- (data$miami_trans_law_t1 + data$miami_trans_law2_t1)/2


# Gender Non-Conformity DV
data$gender_nonconformity_t0 <- compute.factor.dv(gender.nonconformity.t0, data$respondent_t0==1 & !is.na(data$respondent_t0))
data$gender_nonconformity_t1 <- compute.factor.dv(gender.nonconformity.t1, data$respondent_t1==1 & !is.na(data$respondent_t1))
```

## Estimation Procedures

### Contact Rate

```{r, include = FALSE}
# This dummy records whether the intervention was actually delivered vs. was not for any reason.
# Note that we do not use this variable to conduct comparisons only to measure successful contact rates.
data$treatment.delivered <- data$exp_actual_convo == "Trans-Equality" & !is.na(data$canvass_trans_ratingstart)
```

### Complier Average Causal Effect Estimation
To estimate complier average causal effects, we rely on ordinary least squares (OLS) with cluster-robust standard errors, clustering on household and residualizing using pre-treatment covariates from the baseline survey and voter list. This procedure and these covariates were pre-specified in advance and produce unbiased estimates of causal effects (*33*). We also adjust for the contact rate, as described above. Finally, we implement Olken's rejection rule (*43*) as specified in our pre-analysis plan, which denoted the bottom 1\% and top 4\% of the sampling distribution as the rejection region (instead of either the bottom 2.5\% and top 2.5\% or only top 5\% as is conventional). We report p-values for this region and otherwise report "n.s." (*43*). (The only result this rule affects is the 3-month effect on the law index.)

```{r, include=FALSE}
t0.covariate.names <- c('miami_trans_law_t0', 'miami_trans_law2_t0', 'therm_trans_t0', 
'gender_norms_sexchange_t0', 'gender_norms_moral_t0', 'gender_norms_abnormal_t0',
'ssm_t0', 'therm_obama_t0', 'therm_gay_t0','vf_democrat', 'ideology_t0', 
'religious_t0', 'exposure_gay_t0', 'exposure_trans_t0', 'pid_t0', 'sdo_scale',
'gender_norm_daugher_t0', 'gender_norm_looks_t0', 
'gender_norm_rights_t0', 'therm_afams_t0', 'vf_female', 'vf_hispanic',
'vf_black', 'vf_age', 'survey_language_es', 'cluster_level_t0_scale_mean')
x <- data[,c(t0.covariate.names)]
x <- as.matrix(x, dimnames = list(NULL, names(x)))

# Function to compute clustered standard errors, from Mahmood Arai.
cl <- function(fm, cluster){
  M <- length(unique(cluster))
  N <- length(cluster)
  K <- fm$rank
  dfc <- (M/(M-1))*((N-1)/(N-K))
  uj  <- apply(estfun(fm), 2, function(x) tapply(x, cluster, sum))
  vcovCL <- dfc*sandwich(fm, meat=crossprod(uj)/N)
  coeftest(fm, vcovCL)
}

# Function to extract the average treatment effect from OLS with clustered SEs.
est.ate <- function(dv, include.obs = NULL, include.covariates = TRUE){
  if(is.null(include.obs)){
    include.obs <- !is.na(dv) 
  }
  include.obs <- which(include.obs & !is.na(dv))
  
  if(include.covariates) lm.obj <- lm(dv[include.obs] ~ data$treat_ind[include.obs] +
                                        x[include.obs,])
  if(!include.covariates) lm.obj <- lm(dv[include.obs] ~ data$treat_ind[include.obs])
  
  # Calculate cluster-robust standard errors.
  result <- cl(lm.obj, data$hh_id[include.obs])[2,]
  
  # Adjust point estimate and standard error for contact rate in subsample.
  itt_d <- lm(treatment.delivered ~ treat_ind, data[include.obs,])$coefficients[2]
  result[1:2] <- result[1:2] / itt_d
  
  # Per pre-analysis plan, rejection region is top 4% and bottom 1% of sampling distribution,
  # so p-values are reported for this region; otherwise, we write "n.s."
  # See Olken (*43*) , page 70, footnote 5.
  # Note that cl() returns two-tailed p-values that must be converted to one-tailed.
  # Note that all DVs were recoded such that higher values indicated more tolerance.
  result[4] <- result[4] / 2 # p-value corresponds to mass under one side of distribution.
  rejection.region <- ((result[4] < .04 & result[1] > 0) | # Significant positive result.
                         (result[4] < .01 & result[1] < 0)) # Significant negative result.
  result <- round(result, 3)
  if(rejection.region) result[4] <- paste0(as.character(result[4]), "*")
  if(!rejection.region) result[4] <- "*n.s.*"
  if(result[4] == "0*") result[4] <- "0.000*" # Indicate precision of 0 p-value.
  names(result)[4] <- "*p*"
  return(result)
}
```

### Heterogenous Treatment Effects

```{r, include=FALSE}
# Residualized Outcome
t1 <- subset(data, !is.na(trans.tolerance.dv.t1))
x.t1 <- t1[,c(t0.covariate.names)]
x.t1 <- as.matrix(x.t1, dimnames = list(NULL, names(x.t1)))
t1$t1.resid <- summary(lm(t1$trans.tolerance.dv.t1 ~ x.t1))$residuals
write.csv(t1, file = "t1.csv")
```

#### Overall treatment effect by party

```{r,  include = TRUE, eval= TRUE, echo = FALSE}
party <- data.frame(table(t1$vf_party))
pander(t(party))

ggbarplot(t1, x = "vf_party",
      y = c("trans.tolerance.dv.t0", "trans.tolerance.dv.t1"),
      merge = TRUE,
      ylab = "trans tolerance", 
      add = "mean_se", palette = "jco")
```

#### Treatment effect py party: placebo vs treatment 


```{r}
# Replacing word with number in exp_actual_convo 
t1[t1$exp_actual_convo == "Recycling",]$exp_actual_convo = 0
t1[t1$exp_actual_convo == "Trans-Equality",]$exp_actual_convo = 1
t1$exp_actual_convo <- as.numeric(as.character(t1$exp_actual_convo))
```


```{r, echo = FALSE, warning=FALSE}
# placebo <- subset(t1, treat_ind == 0)
# treat <- subset(t1, treat_ind == 1)

placebo <- subset(t1, exp_actual_convo == 0)
treat <- subset(t1, exp_actual_convo == 1)
```

```{r, echo = FALSE, warning=FALSE}
placebo_party <- data.frame(table(placebo$vf_party))
treat_party <- data.frame(table(treat$vf_party))
placebo_treat_party <- cbind(placebo_party, treat_party)
colnames(placebo_treat_party) <- c("0", "placebo", "1", "treat")
pander(t(placebo_treat_party))

ggbarplot(placebo, x = "vf_party",
      y = c("trans.tolerance.dv.t0", "trans.tolerance.dv.t1"),
      merge = TRUE,
      ylab = "trans tolerance", 
      add = "mean_se", palette = "jco", title = "Placebo group")

ggbarplot(treat, x = "vf_party",
      y = c("trans.tolerance.dv.t0", "trans.tolerance.dv.t1"),
      merge = TRUE,
      ylab = "trans tolerance", 
      add = "mean_se", palette = "jco", title = "Treatment group")

```



#### Overall treatment effect by race
```{r,  include = TRUE, eval= TRUE, echo = FALSE}
race <- data.frame(table(t1$vf_racename))
panderOptions('table.caption.prefix','')
pander(t(race))

ggbarplot(t1, x = "vf_racename",
      y = c("trans.tolerance.dv.t0", "trans.tolerance.dv.t1"),
      merge = TRUE,
      ylab = "trans tolerance", 
      add = "mean_se", palette = "jco")
```

#### Treatment effect py race: placebo vs treatment 
```{r, echo = FALSE, warning=FALSE}
placebo_race <- data.frame(table(placebo$vf_racename))
treat_race <- data.frame(table(treat$vf_racename))
placebo_treat_race <- cbind(placebo_race, treat_race)
colnames(placebo_treat_race) <- c("0", "placebo", "1", "treat")
pander(t(placebo_treat_race))

ggbarplot(placebo, x = "vf_racename",
      y = c("trans.tolerance.dv.t0", "trans.tolerance.dv.t1"),
      merge = TRUE,
      ylab = "trans tolerance", 
      add = "mean_se", palette = "jco", title = "Placebo group")

ggbarplot(treat, x = "vf_racename",
      y = c("trans.tolerance.dv.t0", "trans.tolerance.dv.t1"),
      merge = TRUE,
      ylab = "trans tolerance", 
      add = "mean_se", palette = "jco", title = "Treatment group")

```


We searched for heterogenous treatment effects by computing a residualized trans.tolerance.dv.t1 among t1 responders (residualizing using the pre-specified covariates but not the treatment indicator) then testing whether the treatment effect on this residualized index was larger for some subgroups. (Residualizing first makes sure the coefficients on the covariates do not differ within subgroups when we compute estimates within subgroups.) In our pre-analysis plan, we specified three predictions about treatment effect heterogeneity by subject attributes:

1. Democrats will be more treatment-responsive than Republicans as a result of partisan cues being more aligned, 
2. Subjects higher on the baseline support scale will be more treatment-responsive as a result of being more open to outgroups in general, and 
3. Subjects higher in need for cognition will show larger and longer-lasting effects (this scale was only included on the six week survey, so we view this analysis as more exploratory given that it was not measured pre-treatment).

We found evidence for none of these patterns. In the last subsection we also show evidence of insignificant heterogenous treatment effects for a broader set of covariates.

Note that we present tests for the presence of heterogeneous treatment effects for completeness, but the fact that we fail to find such effects may reflect low power meaning we are unable to reject a false null; the below tests should not be construed as our accepting the null of no difference.


#### By Party Registration
We analyze the data two ways. In Table S6, we present the conditional average treatment effect among Democrats, Independents, and Republicans on the trans.tolerance.dv.t1 factor. In Table S7, we present the interaction effect between binary variables for Democrats and Independents and the treatment indicator on the same factor (making Republicans the base category), after having been residualized on the above specified covariates. We find no evidence of heterogeneous treatment effects. (The only hint of a pattern is that Republicans are more affected than Independents.)

Again, recall that because the independent variable has already been residualized, the base terms do not reflect the baseline difference between the groups (e.g., Republicans are indeed less supportive at baseline).


**Table S6.**
```{r, eval=TRUE}

dem <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_democrat == 1))
rep <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_republican == 1))
ind <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_independent == 1))
dem.rep.ind <- cbind(dem, rep, ind)
colnames(dem.rep.ind) <- c("Democrats", "Republicans", "Independents")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, separately. Linear regression with clustered standard errors.")
pander(t(dem.rep.ind))
```

**Table S7.**
```{r, eval=TRUE}
pid.interact <- summary(lm(t1$t1.resid ~ t1$treat_ind * t1$vf_democrat + t1$treat_ind * t1$vf_independent))$coefficients
rownames(pid.interact) <- c("Intercept", "Treatment", "Democrat", "Independent", "Democrat x Treat", "Independent X Treat")
colnames(pid.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(pid.interact)
```


**Table S7b.**
```{r, eval=TRUE}
pid.interact <- summary(lm(t1$t1.resid ~ t1$exp_actual_convo * t1$vf_democrat + t1$exp_actual_convo * t1$vf_independent))$coefficients
rownames(pid.interact) <- c("Intercept", "Treatment", "Democrat", "Independent", "Democrat x Treat", "Independent X Treat")
colnames(pid.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(pid.interact)
```


#### Same sex marriage support
**Table S13a.**
Compute heterogenous treatment effects on a residualized version of the outcome
```{r, eval=TRUE, echo=FALSE}
ssm.interact <- summary(lm(t1$t1.resid ~ t1$treat_ind * t1$ssm_t0))$coefficients
rownames(ssm.interact) <- c("Intercept", "Treatment", "SSM", "SSM x Treat")
colnames(ssm.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(ssm.interact)
```


**Table S13b.**
Compute heterogenous treatment effects on the outcome
```{r, eval=TRUE, echo=FALSE}
ssm.interact <- summary(lm(t1$trans.tolerance.dv.t1 ~ t1$treat_ind * t1$ssm_t0))$coefficients
rownames(ssm.interact) <- c("Intercept", "Treatment", "SSM", "SSM x Treat")
colnames(ssm.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(ssm.interact)
```


**Table S13c.**
Compute heterogenous treatment effects on the outcome
```{r, eval=TRUE, echo=FALSE}
ssm.interact <- summary(lm(t1$trans.tolerance.dv.t1 ~ t1$exp_actual_convo * t1$ssm_t0))$coefficients
rownames(ssm.interact) <- c("Intercept", "Treatment", "SSM", "SSM x Treat")
colnames(ssm.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(ssm.interact)
```


#### Race

**Table S14.**
```{r, eval=TRUE, echo=FALSE}

white <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_white == 1))
hisp <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_hispanic == 1))
black <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_black == 1))
white.h.b <- cbind(white, hisp, black)
colnames(white.h.b) <- c("white", "hisp", "black")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Race Registration, separately. Linear regression with clustered standard errors.")
pander(t(white.h.b))
```


**Table S15a.**
```{r, eval=TRUE, echo=FALSE}
pid.interact <- summary(lm(t1$t1.resid ~ t1$treat_ind * t1$vf_white + t1$treat_ind * t1$vf_hispanic + t1$treat_ind * t1$vf_black))$coefficients
rownames(pid.interact) <- c("Intercept", "Treatment", "White", "Hisp", "Black", "White x Treat", "Hisp X Treat", "Black X Treat")
colnames(pid.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Race Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(pid.interact)
```

**Table S15b.**
```{r, eval=TRUE, echo=FALSE}
pid.interact <- summary(lm(t1$t1.resid ~ t1$exp_actual_convo * t1$vf_white + t1$exp_actual_convo * t1$vf_hispanic + t1$exp_actual_convo * t1$vf_black))$coefficients
rownames(pid.interact) <- c("Intercept", "Treatment", "White", "Hisp", "Black", "White x Treat", "Hisp X Treat", "Black X Treat")
colnames(pid.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Race Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(pid.interact)
```



#### Machine Learning Algorithm for Other Subgroups

There are many other covariates available from the voter file and on our survey. In order to avoid a post hoc hypothesis testing exercise that would likely lead us to find at least one such covariate to predict the treatment effect purely by chance, we also implemented a machine learning procedure designed to automatically search for the existence of any robust heterogenous treatment effects (*44*). The procedure relies on the Lasso, a variable selection algorithm. The results return only the intercept, indicating that none of the covariates predict the treatment effect robustly; the treatment is broadly effective among subgroups. We take this result as propitious for the generalizability of the findings.

```{r}
# Residualize the dependent variable, then transform it per (*44*).
t1.resid <- summary(lm(data$trans.tolerance.dv.t1 ~ x))$residuals
data$t1.resid[as.numeric(names(t1.resid))] <- t1.resid # Maps residuals back into data.
data$transformed.outcome <- with(data, t1.resid * (treat_ind - .5) / .25)

# Vectors describing rows where the outcome was observed.
include.obs <- !is.na(data$transformed.outcome)
x.subset <- cbind(data$treat_ind[include.obs], x[include.obs,])
transformed.outcome <- data$transformed.outcome[include.obs]

# Lasso.
cvfit.lasso <- cv.glmnet(x.subset, transformed.outcome, alpha = 1)
coef(cvfit.lasso, s = "lambda.min")
```



## Further Explanation of and Replication Code for Results in Main Text

### Results In Main Text

* "After the intervention, the treatment group was considerably more accepting of transgender people than the placebo group (t = 4.03; p < 0.001)."
```{r}
est.ate(data$trans.tolerance.dv.t1)
```


* "These effects are substantively large: these brief conversations increased positivity towards transgender people on a feeling thermometer (20, 21) by approximately 10 points, an amount larger than the secular increase in positive affect towards gay men and lesbians among Americans between 1998 and 2012 (8.5 points; see table S22)."

```{r}
est.ate(data$therm_trans_t1)
```


## Descriptive memo 

Cleaning data for analyses on only on t1. Therefore removing other columns that are relavant for t2, t3 and t4. 

```{r}
# Removing all results of t2 (3 week), t3 (6 week) and t4 (3 month) 
t1_results <- t1[, -which(grepl('t2|t3|t4', names(t1)))]

# Pre-specified index of all primary outcomes at t0
all.dv.names.t0 <- c('miami_trans_law_t0', 'miami_trans_law2_t0', 'therm_trans_t0',
                      'gender_norms_sexchange_t0', 'gender_norms_moral_t0',
                      'gender_norms_abnormal_t0', 'gender_norm_trans_moral_wrong_t0')

# Remove primary outcomes at t0 and t1
t1_related <- t1_results[ , !(names(t1_results) %in% all.dv.names.t1)]
t1_related <- t1_related[ , !(names(t1_related) %in% all.dv.names.t0)]

# Remove gender non-conformity index at t0 and t1 since they used for
t1_related <- t1_related[ , !(names(t1_related) %in% gender.nonconformity.t0)]
t1_related <- t1_related[ , !(names(t1_related) %in% gender.nonconformity.t1)]

# Remove index relavant to canvasser
t1_related <- t1_related[, -which(grepl('canvass|canvasser', names(t1_related)))]

# Remove categorical variables 
t1_related <- t1_related[, -which(grepl('vf_racename|vf_party', names(t1_related)))]

# Remove identifiers
identifiers <- c('id', 'block_ind', 'hh_id')
t1_related <- t1_related[ , !(names(t1_related) %in% identifiers)]

# Remove contacted or responded (as they are all ones in this case)
tracking <- c('respondent_t0', 'respondent_t1', 'contacted')
t1_related <- t1_related[ , !(names(t1_related) %in% tracking)]

# Remove index that are directly related to the survey 
survey_method <- c('scale_for_blocking_t0', 'cluster_level_t0_scale_mean','survey_language_t0', 'survey_language_es')
t1_related <- t1_related[ , !(names(t1_related) %in% survey_method)]


# Replacing word with number in exp_actual_convo 
#t1_related[t1_related$exp_actual_convo == "Recycling",]$exp_actual_convo = 0
#t1_related[t1_related$exp_actual_convo == "Trans-Equality",]$exp_actual_convo = 1
#t1_related$exp_actual_convo <- as.numeric(as.character(t1_related$exp_actual_convo))

# Removing treat_ind because it is assigned treatment and actual treatment is in exp_actual_convo
t1_related <- t1_related[ , !(names(t1_related) %in% "treat_ind")]

# Drop index related to marijuana 
t1_related <- t1_related[, -which(grepl('marijuana', names(t1_related)))]
```

```{r}
df_split_trans <- modelr::resample_partition(t1_related, c(train=0.5, estim=0.5))
df_train_trans <- dplyr::as_tibble(df_split_trans$train)
df_est_trans<- dplyr::as_tibble(df_split_trans$estim)

outcome <- "trans.tolerance.dv.t1"
treatment <- "exp_actual_convo"
contexts <- colnames(t1_related)[1:24]
contexts <- contexts[contexts != treatment]
```

## Summarize context variables

```{r, results="asis", message=FALSE, echo=FALSE}
summarize_contexts(t1_related[c(outcome, contexts)])
```

## X-learners

```{r, echo = FALSE}
cates <- map("exp_actual_convo", function(level) {
 
  level <- treatment
  
  X_train <- as.data.frame(df_train_trans[contexts])
  W_train <- pull(df_train_trans, level)
  Y_train <- pull(df_train_trans, outcome)
  X_test <-  as.data.frame(df_est_trans[contexts])
  xls <- hte::X_RF(feat = X_train,
                   tr = W_train,
                   yobs = Y_train,
                   ntree_first = 500,
                   ntree_second = 500,
                   ntree_prop = 500,
                   nthread = 1,
                   min_node_size_spl_first = 1,
                   min_node_size_ave_first = 1,
                   min_node_size_spl_second = 1,
                   min_node_size_ave_second = 1,
                   min_node_size_spl_prop = 1, 
                   min_node_size_ave_prop = 1)
  
  cate <- hte::EstimateCate(xls, X_test) %>% as_tibble() %>% rename(cate=value)
  
  data_with_cate <- bind_cols(df_est_trans, cate)

})

names(cates) <- "exp_actual_convo"
```

```{r, results="asis", message=FALSE, eval=TRUE,  echo = FALSE}
# Prints html table
walk2(cates, names(cates), function(data_with_cate, title) {
    # overall title
  Leaf_title <- str_c("\n<h4> ", title," </h4>\n")
  cat(Leaf_title)
  
  # Computes the ntiles of the "cate" column
  data_with_ntiles <- add_ntiles(data_with_cate, ntiles=5)
  
  # Multiple hyp. testing for context means given factor(ntiles). Keeps if at least 1 significant
  significant_contexts <- keep(contexts, ~has_significant(data_with_ntiles, ., "cate_ntile"))
  
  # Creates a table based on tile
  tab <- summarize_by_prediction_ntile(data=data_with_ntiles,
                                       covariates=significant_contexts,
                                       ntiles=5)
  
  # Prettyprint with HTML+Boostrap
  html <- pretty_table(tab, digits=2, title=title, prefix="Q")
  
  cat(html)
  
})
```


# Post-lasso
```{r, echo = FALSE}
 simple_post_lasso <- function(y_column, x_columns, w_columns, data) {
  # Prepare matrices
  x_fmla <- make_formula(x=x_columns)
  w_fmla <- make_formula(w=w_columns)
  xw_fmla <- make_formula(x=x_columns, w=w_columns, include_x=FALSE, include_w=FALSE)
  regressors_x <- model.matrix(x_fmla, data = data)[,-1] # Drops intercept (sigh)
  regressors_w <- as.data.frame(model.matrix(w_fmla, data = data)[,-1])
  colnames(regressors_w) <- "exp_actual_convo"
  regressors_xw <- model.matrix(xw_fmla, data = data)[,-1]

  regressand <- dplyr::pull(data, y_column)

  # Scale regressors associated with contexts
  regressors_x <- scale(regressors_x, center=TRUE, scale=FALSE)

  # Collect all regressors
  regressors <- cbind(regressors_x, regressors_w, regressors_xw)
  regressors <- as.matrix(regressors)
  # Set penalty factors to zero for treatment main effects
  penalty_factor <- c(rep(1, ncol(regressors_x)),
                      rep(0, ncol(regressors_w)),
                      rep(1, ncol(regressors_xw)))

  # Run glmnet, get regressors associated with nonzero coefficients
  lasso <- glmnet::cv.glmnet(
    x=regressors,
    y=regressand,
    penalty.factor=penalty_factor,
    alpha=1,            # alpha==1 means LASSO
    standardize=FALSE,  # Regressors were already centered
    intercept=TRUE)    # Not included in model.matrix by default

  nonzero <- coef(lasso, s=lasso$lambda.min) %>%
    as.matrix %>%
    .[which(. != 0),] %>% names()  %>% # Grab names
    .[!grepl("Intercept", .)]  # Discard intercept

  # Run OLS
  fmla_post <- make_formula(y="y", x=nonzero)
  data_post <- regressors %>%
    dplyr::as_tibble(.) %>%
    dplyr::mutate(y=dplyr::pull(data, y_column))
  ols <- lm(fmla_post, data_post)

  return(ols)
}
```

```{r, echo = FALSE}
pl <- simple_post_lasso(
    y_column=outcome,
    x_columns=contexts,
    w_columns=treatment,
    data=t1_related
  )

pretty_table(summary(pl)$coef)
```


# Causal Tree 

### Correlation table by cate leaf

```{r, echo=FALSE, message=FALSE, results="asis", warning=FALSE, eval=TRUE}
get_cor_column <- function (table, correlation, level){
   # order rows by correlation
  table <- merge(table, correlation, by = "Variable")
  table %>%
    arrange(-abs(cor)) %>% 
    filter(Variable!="cate") -> table  #remove row "cate"
  
  # extract cor and cor_pval columns
  cor_value <- round(table$cor, digits = 2)
  p <- table$cor_pval
  
  var_names <- table %>% select("Variable")
  
  # Define notions for significance levels; spacing is important.
  significance <- ifelse(p < .01, "*** ", ifelse(p < .05, "**  ", ifelse(p < .1, "*   ", "    ")))
  
  cor_table_1 <- matrix(paste(cor_value, significance, sep=""), ncol=1)
  colnames(cor_table_1) <- level
  
  cor_table_1 <- cbind(var_names, cor_table_1)
  rownames(table ) <- NULL # numbers generated when sorting, need to remove for html 
  tables <- list("table_1" = table, "cor_table_1" = cor_table_1)
 
  return(tables)
}

```

```{r, echo = FALSE}
summarize_var_by_prediction_leaves <- function(data, covariates, level, outcome,...) {
  # Groups together
  grp <- data %>% dplyr::group_by(leaf_id)

  # so in addition to covars, we also want to see cate
  vars_of_interest <- c(covariates, "cate")

  # Computes the mean and sem of each covariate
  means <- grp %>%
    dplyr::select(leaf_id, vars_of_interest ) %>%
    dplyr::summarise_all(mean) %>%
    dplyr::arrange(-cate)

  leaf_means <- t(means) %>% .[-1,] %>% # transpose and drop the leaf row
    as.data.frame()

  # Adds row and column names
  leaf_means <- leaf_means %>% rownames_to_column
  colnames(leaf_means) <- c("Variable", 1:(ncol(leaf_means) -1) )

  # finding difference between biggest leaf and little leaf
  # can only do this if there is one
  if (ncol(leaf_means) > 2){
    max_leaf <- means %>% filter(cate == max(cate)) %>% select(leaf_id) %>% as.numeric()
    min_leaf <- means %>% filter(cate == min(cate)) %>% select(leaf_id) %>% as.numeric()
    # do t-test for the contexts
    data %>%
      dplyr::select(leaf_id, vars_of_interest) %>%
      tidyr::gather(key = variable, value = value, -leaf_id) %>%
      dplyr::group_by(leaf_id, variable) %>%
      dplyr::summarise(value = list(value)) %>%
      tidyr::spread(leaf_id, value) %>%
      group_by(variable) %>%
      dplyr::select("variable",as.character(c(min_leaf, max_leaf))) %>%
      dplyr::filter(variable != "cate") -> df_list_leaf_vals
    colnames(df_list_leaf_vals) <-  c("Variable", "min_leaf", "max_leaf")
    # if there is no variance in the leaves then t.test can not be found
    df_list_leaf_vals %>% dplyr::mutate(sum_var = sum(var(unlist(min_leaf)),
                                               var(unlist(max_leaf)))) %>%
      dplyr::mutate(p_value = ifelse(sum_var == 0, NA, t.test(unlist(min_leaf),
                                                       unlist(max_leaf))$p.value)) -> final_context_pvalues
    # do the t-test for CATE
    data %>%
      dplyr::select(level, "leaf_id", outcome) %>%
      dplyr::filter(leaf_id %in% c(min_leaf, max_leaf)) %>%
      dplyr::mutate(leaf_id = ifelse(leaf_id == min_leaf, "min_leaf","max_leaf")) -> mod_data

    leaf_mod <- lm(as.formula(paste0(outcome, " ~ ", "leaf_id:", level)),
                   data =  mod_data)

    leaf_test <- broom::tidy(car::linearHypothesis(leaf_mod,
                                              paste0("leaf_idmin_leaf:",level,
                                                     " = ", "leaf_idmax_leaf:", level)))
    final_cate_pvalue <- data.frame(Variable = c("cate"),
                                    p_value = leaf_test$p.value[2])
    final_pvalues <- rbind(final_context_pvalues[c("Variable", "p_value")], final_cate_pvalue)

    leaf_means <- merge(leaf_means, final_pvalues, by = "Variable")
  }

  leaf_means
}
```

```{r, echo = FALSE}

# Other treatments and levels are seen as regular covariates
fmla <- make_formula(y=outcome,
                     x=contexts,
                     w=treatment,
                     include_xw=FALSE,
                     include_intercept=TRUE) # Due to CT bug

# Fit and cross-validate an __honest__ causal tree
ctree <- fit_causal_tree(formula=fmla,
                         w=treatment,
                         df_train = df_train_trans,
                         df_est = df_est_trans, 
                         minsize = 7)

# Predict leaf it on new set
df_est_trans[,"leaf_id"] <- treeClust::rpart.predict.leaves(ctree,
                                                      df_est_trans, type="where")

cate <- as_tibble(predict(ctree, newdata = df_est_trans)) %>% rename(cate=value)

# Adds this as a column called "cate"
data_with_cate <- bind_cols(df_est_trans, cate)

# Computes the ntiles of the "cate" column
data_with_ntiles <- add_ntiles(data_with_cate, ntiles=5)


table_1 <- summarize_var_by_prediction_leaves(data=data_with_ntiles, 
                                       covariates= contexts,
                                       level = treatment, 
                                       outcome = outcome)

# find correlation so we can sort out rows by it, need more than 1 leaf
if (ncol(table_1) > 3){
  
  cor_leaf <- correlation_with_cate_by_variable(data=data_with_ntiles, 
                                                covariates= contexts,
                                                ntiles=5,
                                                group_by_var="leaf_id")
  hmtl_table_1 <- pretty_table(table_1)
  
  #create table with correlation and p-val while keeping the original table_1 
  tables <- get_cor_column(table = table_1,
                           correlation = cor_leaf, level = treatment)
  
}

tables$cor_table_1
```

