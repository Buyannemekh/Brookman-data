---
title: "broockman_kalla"
author: "Buyannemekh Munkhbat"
date: "10/25/2018"
output:
  html_document: default
  pdf_document: default
---

```{r, include=FALSE}
rm(list = ls())
library(foreign)
library(pander)
library(plyr)
library(sandwich)
library(lmtest)
library(data.table)
library(ggplot2)
library(reshape2)
library(glmnet)
library(memoutils)
library(dplyr)
library(purrr)


library(devtools)
library(tidyverse)
library(rprojroot)

library(kableExtra)
library(knitr)
library(tibble)
library(magrittr)
library(aod)
library(broom)
library(grid)
library(gridExtra)

library(ggpubr)
library(ggplot2)
wd <- '' # enter your working directory here
set.seed(5953921)

data <- read.dta(paste0(wd, 'broockman_kalla_replication_data.dta'))
# Note: Variables that begin with vf_ come from the voter file.
# Variables that end with _t0 were collected on the baseline survey.
```


### Items Capturing Primary Outcomes Appearing on All Surveys

The below items appeared on multiple surveys; the # sign below will be replaced with the survey number in our analysis:

* The baseline survey is survey 0;
* the 3-day survey is survey 1;
* the 3-week survey is survey 2;
* the 6-week survey is survey 3, and;
* the 3-month survey is survey 4.

Item names appear in bold next to each item. For the remainder of the paper we will refer to these items by these bolded names.

* **miami_trans_law_t#**: Miami-Dade county recently passed a law that prohibits discrimination in housing, employment and public accommodations based on gender identity and expression, a category that includes transgender men and women [for **miami_trans_law_withdef_t#**, adds the phrase here, "(people who were designated one gender at birth, but now identify as a different gender)."]. Do you favor or oppose this new law?
* **miami_trans_law2_t#**: Some people say it's important to protect transgender people from discrimination in housing and employment. Other people have concerns about society becoming too accepting of transgender people, and do not want transgender people included in our non-discrimination law. What do you think? Do you agree or disagree that Miami law should protect transgender people [for **miami_trans_law2_withdef_t#**, adds the phrase here, "(people who were designated one gender at birth, but now identify as a different gender)."] from discrimination?
* **trans_law_post_ad_t3**: On the third survey only, we asked about the law again after showing an opposition video: "We've mentioned that Miami-Dade county recently passed a law that prohibits discrimination in housing, employment and public accommodations based on gender identity and expression, a category that includes transgender men and women (people who were designated one gender at birth, but now identify as a different gender). After seeing the video, do you favor or oppose this new law?" This item does not appear in any of the scales.
* **therm_trans_t#**: Feeling thermometer towards trans people (0-100) (From *(39)*)
* **gender_norm_abnormal_t#**: A man who identifies as a woman is psychologically abnormal (Modification from (*40, 41*)).
* **gender_norm_moral_t#**: It is morally wrong for a man to present himself as a woman in public (Modification from (*40*)).
* **gender_norm_trans_moral_wrong_t#**: Saying you are a gender that is different than the one you were born with is morally wrong (Modification from (*40, 41*)).
* **gender_norm_sexchange_t#**: I would support a friend choosing to have a sex change (Modification from (*42*)).

Starting with the second post-treatment survey, we also asked the below two items.  These items were composed and added after examining the results from the first post-treatment survey. An amended pre-analysis plan was submitted to EGAP to reflect the addition of these two questions.

* **trans_teacher_t#**: Transgender women (people who identify as women but were designated male at birth) should be allowed to serve as public school teachers.
* **trans_bathroom_t#**: It would be wrong to allow a transgender woman (a person who identifies as a woman but was designated male at birth) to use the woman’s restroom (Modification from (*40*)).

### Outcome Indices

In our pre-analysis plan, we specified that we would combine multiple items into indices to test hypotheses. Combining outcomes into an index increases precision by decreasing survey measurement error and limits the potential for multiple hypothesis testing (*33*).

The indicies, to be described momentarily, are as follows:

* **all.dvs.t#**: An index of all primary outcomes, created to test the omnibus hypothesis that the treatment had any effects.
* **trans.tolerance.dv.t#**: An index of outcomes from all.dvs.t# capturing acceptance and tolerance towards -- instead of prejudice and stigma towards -- transgender people; this is all primary outcomes except for the two items about the law.
* **miami_trans_law_t#_avg**: An index of the two items about Miami's law protecting transgender people from discrimination in housing, employment, and public accomodations. Because these items were Likert scales with the same number of points and there were only two of them, the index is a simple average of the two items.
* **gender_nonconformity_t#**: Distinct from measuring transgender tolerance, we also constructed a scale capturing gender norms. As stated in our pre-analysis plan, effects on this measure represented a secondary hypothesis and this index is not a primary outcome of interest. (However, there do appear to be effects on this measure as well, but we do not discuss these in the main text due to space constraints.)

#### Pre-Specified Index of All Primary Outcomes

In the pre-analysis plan we indicated that the main hypothesis test will be whether an index of all primary outcomes shows statistical significance. We list these outcomes for each survey below. (In the pre-analysis plan we called this "main.dv.")

Note that we code the scale such that larger, more positive values indicate more tolerance and less prejudice.

```{r}
all.dv.names.t1 <- c('miami_trans_law_t1', 'miami_trans_law2_t1', 'therm_trans_t1',
                      'gender_norm_sexchange_t1', 'gender_norm_moral_t1',
                      'gender_norm_abnormal_t1', 'gender_norm_trans_moral_wrong_t1')
```

#### Transgender Tolerance Index

```{r}
trans.tolerance.dvs.t0 <- c('therm_trans_t0', 'gender_norms_sexchange_t0',
                            'gender_norms_moral_t0', 'gender_norms_abnormal_t0')

trans.tolerance.dvs.t1 <- c('therm_trans_t1', 'gender_norm_sexchange_t1',
                            'gender_norm_moral_t1', 'gender_norm_abnormal_t1',
                            'gender_norm_trans_moral_wrong_t1')
```

#### Law Items Index
```{r}
trans.law.dvs.t0 <- c('miami_trans_law_t0', 'miami_trans_law2_t0')
trans.law.dvs.t1 <- c('miami_trans_law_t1', 'miami_trans_law2_t1')
```


#### Secondary Outcome: Gender Non-Conformity Index
```{r}
gender.nonconformity.t0 <- c('gender_norm_looks_t0', 'gender_norm_rights_t0')
gender.nonconformity.t1 <- c('gender_norm_looks_t1', 'gender_norm_rights_t1')
```

### Reverse Coded Items
```{r, include = FALSE}
reverse.coded.items <- c('gender_norms_moral_t0', 'gender_norm_moral_t1',
                         'gender_norm_moral_t2', 'gender_norm_moral_t3',
                         'gender_norm_moral_t4', 'gender_norms_abnormal_t0',
                         'gender_norm_abnormal_t1', 'gender_norm_abnormal_t2',
                         'gender_norm_abnormal_t3','gender_norm_abnormal_t4',
                         'gender_norm_trans_moral_wrong_t1', 
                         'gender_norm_trans_moral_wrong_t2',
                         'gender_norm_trans_moral_wrong_t3',
                         'gender_norm_trans_moral_wrong_t4',
                         'trans_bathroom_t2', 'trans_bathroom_t3',
                         'trans_bathroom_t4', 'gender_norm_looks_t0',
                         'gender_norm_looks_t1', 'gender_norm_looks_t2',
                         'gender_norm_looks_t3', 'gender_norm_looks_t4',
                         'gender_norm_rights_t0', 'gender_norm_rights_t1',
                         'gender_norm_rights_t2', 'gender_norm_rights_t3',
                         'gender_norm_rights_t4', 'gender_norm_dress_t2',
                         'gender_norm_dress_t3', 'gender_norm_dress_t4')
for(item in reverse.coded.items) data[,item] <- -1 * data[,item]
```

### Procedue for Combining Outcomes into Indices


```{r}
# Compute factor analysis outcome
compute.factor.dv <- function(dv.names, respondent.booleans, print.loadings = TRUE){
  responders <- data[respondent.booleans,]
  
  # Factor analysis
  factor.obj <- princomp(responders[, dv.names], cor=TRUE)
  if(print.loadings) print(loadings(factor.obj))
  dv <- as.vector(factor.obj$scores[,1])
  
  # More positive values on the factor should indicate more tolerance; reverse otherwise.
  if(cor(dv, responders$miami_trans_law_t0, use="complete.obs") < 0) dv <- -1 * dv
  
  # Put in the order of the main data frame
  dv.in.order <- dv[match(data$id, responders$id)]
  
  # Rescale to mean 0 sd 1 in placebo group; treatment effects can then be interpreted
  # as the effect in standard deviations the treatment would have among an untreated
  # population.
  dv.in.order <- (dv.in.order - mean(dv.in.order[!data$treat_ind], na.rm=TRUE)) /
    sd(dv.in.order[!data$treat_ind], na.rm=TRUE)
  
  return(as.vector(dv.in.order))
}
```

```{r}
# In this code section we implement the procedures describe previously.

# First, misc. housekeeping.
# Recode age for small number of observations where it is missing.
data$vf_age[which(is.na(data$vf_age))] <- mean(data$vf_age, na.rm=TRUE)

# Language of interview
data$survey_language_es[is.na(data$survey_language_es)] <-
    data$survey_language_t0[is.na(data$survey_language_es)] == "ES"
data$survey_language_es[is.na(data$survey_language_es)] <- mean(data$survey_language_es, na.rm = TRUE)

# We subset to only those who came to door. contacted = came to door.
full.data <- data
data <- subset(data, contacted == 1)

# Compute the DVs in line with the above procedures.

# Omnibus DV of all primary outcomes.
data$all.dvs.t1 <- compute.factor.dv(all.dv.names.t1, data$respondent_t1==1 & !is.na(data$respondent_t1))


# Trans tolerance DV.
data$trans.tolerance.dv.t0 <- compute.factor.dv(trans.tolerance.dvs.t0, data$respondent_t0==1 & !is.na(data$respondent_t0))
data$trans.tolerance.dv.t1 <- compute.factor.dv(trans.tolerance.dvs.t1, data$respondent_t1==1 & !is.na(data$respondent_t1))


# Law DV.
# Create outcome scale by averaging over the two questions.
data$miami_trans_law_t0_avg <- (data$miami_trans_law_t0 + data$miami_trans_law2_t0)/2
data$miami_trans_law_t1_avg <- (data$miami_trans_law_t1 + data$miami_trans_law2_t1)/2


# Gender Non-Conformity DV
data$gender_nonconformity_t0 <- compute.factor.dv(gender.nonconformity.t0, data$respondent_t0==1 & !is.na(data$respondent_t0))
data$gender_nonconformity_t1 <- compute.factor.dv(gender.nonconformity.t1, data$respondent_t1==1 & !is.na(data$respondent_t1))
```


## Estimation Procedures

### Contact Rate

```{r}
# This dummy records whether the intervention was actually delivered vs. was not for any reason.
# Note that we do not use this variable to conduct comparisons only to measure successful contact rates.
data$treatment.delivered <- data$exp_actual_convo == "Trans-Equality" & !is.na(data$canvass_trans_ratingstart)
```

### Complier Average Causal Effect Estimation
To estimate complier average causal effects, we rely on ordinary least squares (OLS) with cluster-robust standard errors, clustering on household and residualizing using pre-treatment covariates from the baseline survey and voter list. This procedure and these covariates were pre-specified in advance and produce unbiased estimates of causal effects (*33*). We also adjust for the contact rate, as described above. Finally, we implement Olken's rejection rule (*43*) as specified in our pre-analysis plan, which denoted the bottom 1\% and top 4\% of the sampling distribution as the rejection region (instead of either the bottom 2.5\% and top 2.5\% or only top 5\% as is conventional). We report p-values for this region and otherwise report "n.s." (*43*). (The only result this rule affects is the 3-month effect on the law index.)

```{r}
t0.covariate.names <- c('miami_trans_law_t0', 'miami_trans_law2_t0', 'therm_trans_t0', 
'gender_norms_sexchange_t0', 'gender_norms_moral_t0', 'gender_norms_abnormal_t0',
'ssm_t0', 'therm_obama_t0', 'therm_gay_t0','vf_democrat', 'ideology_t0', 
'religious_t0', 'exposure_gay_t0', 'exposure_trans_t0', 'pid_t0', 'sdo_scale',
'gender_norm_daugher_t0', 'gender_norm_looks_t0', 
'gender_norm_rights_t0', 'therm_afams_t0', 'vf_female', 'vf_hispanic',
'vf_black', 'vf_age', 'survey_language_es', 'cluster_level_t0_scale_mean')
x <- data[,c(t0.covariate.names)]
x <- as.matrix(x, dimnames = list(NULL, names(x)))

# Function to compute clustered standard errors, from Mahmood Arai.
cl <- function(fm, cluster){
  M <- length(unique(cluster))
  N <- length(cluster)
  K <- fm$rank
  dfc <- (M/(M-1))*((N-1)/(N-K))
  uj  <- apply(estfun(fm), 2, function(x) tapply(x, cluster, sum))
  vcovCL <- dfc*sandwich(fm, meat=crossprod(uj)/N)
  coeftest(fm, vcovCL)
}

# Function to extract the average treatment effect from OLS with clustered SEs.
est.ate <- function(dv, include.obs = NULL, include.covariates = TRUE){
  if(is.null(include.obs)){
    include.obs <- !is.na(dv) 
  }
  include.obs <- which(include.obs & !is.na(dv))
  
  if(include.covariates) lm.obj <- lm(dv[include.obs] ~ data$treat_ind[include.obs] +
                                        x[include.obs,])
  if(!include.covariates) lm.obj <- lm(dv[include.obs] ~ data$treat_ind[include.obs])
  
  # Calculate cluster-robust standard errors.
  result <- cl(lm.obj, data$hh_id[include.obs])[2,]
  
  # Adjust point estimate and standard error for contact rate in subsample.
  itt_d <- lm(treatment.delivered ~ treat_ind, data[include.obs,])$coefficients[2]
  result[1:2] <- result[1:2] / itt_d
  
  # Per pre-analysis plan, rejection region is top 4% and bottom 1% of sampling distribution,
  # so p-values are reported for this region; otherwise, we write "n.s."
  # See Olken (*43*) , page 70, footnote 5.
  # Note that cl() returns two-tailed p-values that must be converted to one-tailed.
  # Note that all DVs were recoded such that higher values indicated more tolerance.
  result[4] <- result[4] / 2 # p-value corresponds to mass under one side of distribution.
  rejection.region <- ((result[4] < .04 & result[1] > 0) | # Significant positive result.
                         (result[4] < .01 & result[1] < 0)) # Significant negative result.
  result <- round(result, 3)
  if(rejection.region) result[4] <- paste0(as.character(result[4]), "*")
  if(!rejection.region) result[4] <- "*n.s.*"
  if(result[4] == "0*") result[4] <- "0.000*" # Indicate precision of 0 p-value.
  names(result)[4] <- "*p*"
  return(result)
}
```

### Heterogenous Treatment Effects

We searched for heterogenous treatment effects by computing a residualized trans.tolerance.dv.t1 among t1 responders (residualizing using the pre-specified covariates but not the treatment indicator) then testing whether the treatment effect on this residualized index was larger for some subgroups. (Residualizing first makes sure the coefficients on the covariates do not differ within subgroups when we compute estimates within subgroups.) In our pre-analysis plan, we specified three predictions about treatment effect heterogeneity by subject attributes:

1. Democrats will be more treatment-responsive than Republicans as a result of partisan cues being more aligned, 
2. Subjects higher on the baseline support scale will be more treatment-responsive as a result of being more open to outgroups in general, and 
3. Subjects higher in need for cognition will show larger and longer-lasting effects (this scale was only included on the six week survey, so we view this analysis as more exploratory given that it was not measured pre-treatment).

We found evidence for none of these patterns. In the last subsection we also show evidence of insignificant heterogenous treatment effects for a broader set of covariates.

Note that we present tests for the presence of heterogeneous treatment effects for completeness, but the fact that we fail to find such effects may reflect low power meaning we are unable to reject a false null; the below tests should not be construed as our accepting the null of no difference.

```{r}
# Residualized Outcome
t1 <- subset(data, !is.na(trans.tolerance.dv.t1))
x.t1 <- t1[,c(t0.covariate.names)]
x.t1 <- as.matrix(x.t1, dimnames = list(NULL, names(x.t1)))
t1$t1.resid <- summary(lm(t1$trans.tolerance.dv.t1 ~ x.t1))$residuals
t1_only <- t1[sapply(t1, function(t1) !any(is.na(t1)))]

# dropping variables that is related to canvassers
drop.cols <- c('survey_language_t0', 'trans_ad_displayed_t3', 'exp_actual_convo',
               'canvass_recycling_rating', 'canvasser_experience', 'hh_id', 
               'block_ind')
t1_only %>% select(-one_of(drop.cols)) -> t1_only

t1_only_dummified <- fastDummies::dummy_cols(t1_only)
drop.cols.dummified <- c('id', 'vf_party', 'vf_racename', ' ')
t1_only_dummified %>% select(-one_of(drop.cols.dummified)) -> t1_only_dummified

write.csv(t1_only_dummified, file = "t1_dummified.csv", row.names = FALSE)
write.csv(t1_only, file = "t1_data.csv")
write.csv(t1, file = "t1.csv")
```

```{r}
ggbarplot(t1, x = "vf_party", y = "trans.tolerance.dv.t0", 
          add = c("mean_se", "jitter"),
          color = "vf_party", palette = "jco",
          position = position_dodge(0.8))


ggbarplot(t1, x = "vf_party", y = "trans.tolerance.dv.t1", 
          add = c("mean_se", "jitter"),
          color = "vf_party", palette = "jco",
          position = position_dodge(0.8))
```


```{r}
## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}
```


```{r}
tol_t0 <- summarySE(t1, measurevar="trans.tolerance.dv.t0", groupvars=c("vf_party"))
tol_t0

tol_t1 <- summarySE(t1, measurevar="trans.tolerance.dv.t1", groupvars=c("vf_party"))
tol_t1

```


```{r, fig.width=8, fig.height=8, warning=FALSE}
# Estimate the treatment effect for ALL canvassers
t1.all <- est.ate(data$trans.tolerance.dv.t1)

# Estimate the treatment effect by trans and cis canvassers
#At 3 day survey
t1.trans <- est.ate(data$trans.tolerance.dv.t1,
                    data$canvasser_trans == 1)
t1.cis <- est.ate(data$trans.tolerance.dv.t1,
                  data$canvasser_trans == 0)


# Make DF of summary stats
summary.stats.df <- as.data.frame(rbind(t1.all, 
                          t1.trans, t1.cis),
                          stringsAsFactors = FALSE)

# Change from strings back to numeric, and remove t- and p-values, which are not used.
summary.stats.df <- summary.stats.df[,1:2]
summary.stats.df[,1] <- as.numeric(summary.stats.df[,1])
summary.stats.df[,2] <- as.numeric(summary.stats.df[,2])

# Better variable names
names(summary.stats.df) <- c("point.estimate", "se")

# Map row names of summary.stats.df into days
unique.days <- c(3, 3*7, 6*7, 12*7)
summary.stats.df$days <- unique.days[as.numeric(substr(row.names(summary.stats.df), 2, 2))]

# Read canvasser group from row names
canvasser.label.map <- list(all = "All",
                            tra = "Transgender/Gender\nNon-Conforming Only",
                            cis = "Non-Transgender Only")
summary.stats.df$Canvasser <- factor(as.character(
  canvasser.label.map[substr(row.names(summary.stats.df), 4, 6)]
  ))

# X position of different canvasser groups
summary.stats.df$xpos <- with(summary.stats.df, days + as.numeric(Canvasser) -
                                mean(as.numeric(Canvasser)))

# Point estimate Y
summary.stats.df$point.estimate.y <- summary.stats.df$point.estimate
  # Fix text overlap of point estimate labels.
  summary.stats.df$point.estimate.y[9] <- summary.stats.df$point.estimate.y[9] + .003
  summary.stats.df$point.estimate.y[3] <- summary.stats.df$point.estimate.y[3] - .003

# Compute CIs
summary.stats.df$se.high <- summary.stats.df$point.estimate + summary.stats.df$se
summary.stats.df$se.low <- summary.stats.df$point.estimate - summary.stats.df$se
summary.stats.df$ci.high <- summary.stats.df$point.estimate + summary.stats.df$se * 1.96
summary.stats.df$ci.low <- summary.stats.df$point.estimate - summary.stats.df$se * 1.96

summary.stats.df$point.estimate.label <- paste0(round(summary.stats.df$point.estimate,
                                                      2)," SDs")

g <- ggplot(summary.stats.df,
            aes(x=xpos, y=point.estimate,
                group=Canvasser, color=Canvasser)) +
  theme_classic() +
  # CIs
  geom_linerange(aes(ymin=se.low, ymax=se.high), lwd=1) +
  geom_linerange(aes(ymin=ci.low, ymax=ci.high)) +
  # Point estimate points
  geom_point(color="black") +
  # Point estimate markers
  annotate("text", label=summary.stats.df$point.estimate.label,
           x = summary.stats.df$xpos + 6.3,
           y = summary.stats.df$point.estimate.y,
           size = 3) +
  # Canvassing treatment line / label
  geom_vline(xintercept = 0, linetype = "dashed") +
  annotate("text", label = "Canvassing Treatment",
           x = -1.5, y = .3, size = 3.5, angle = 90) +
  # Day labels
  annotate("text",
           label = c("+3 Days", "+3 Weeks", "+6 Weeks", "+3 Months"),
           x = unique.days, y = -.04,
           colour = "black", size = 3) +
  # Y axis
  ylab("Effect on Transgender Tolerance Scale, in Standard Deviations") + 
  scale_y_continuous() +
  # X axis
  xlab("Days After Canvassing Treatment") +
  geom_hline(yintercept = 0) +
  # Overall Title and Legend
  ggtitle("Differences Between Treatment and Placebo") +
  guides(fill=FALSE) +
  theme(legend.position = "bottom")
ggsave("figure1.pdf", g, width=8, height=6, units="in")


```
#### By Party Registration
We analyze the data two ways. In Table S6, we present the conditional average treatment effect among Democrats, Independents, and Republicans on the trans.tolerance.dv.t1 factor. In Table S7, we present the interaction effect between binary variables for Democrats and Independents and the treatment indicator on the same factor (making Republicans the base category), after having been residualized on the above specified covariates. We find no evidence of heterogeneous treatment effects. (The only hint of a pattern is that Republicans are more affected than Independents.)

Again, recall that because the independent variable has already been residualized, the base terms do not reflect the baseline difference between the groups (e.g., Republicans are indeed less supportive at baseline).

**Table S6.**
```{r, eval=TRUE}

dem <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_democrat == 1))
rep <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_republican == 1))
ind <- data.frame(est.ate(data$trans.tolerance.dv.t1, data$vf_independent == 1))
dem.rep.ind <- cbind(dem, rep, ind)
colnames(dem.rep.ind) <- c("Democrats", "Republicans", "Independents")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, separately. Linear regression with clustered standard errors.")
pander(t(dem.rep.ind))
```

**Table S7.**
```{r, eval=TRUE}
pid.interact <- summary(lm(t1$t1.resid ~ t1$treat_ind * t1$vf_democrat + t1$treat_ind * t1$vf_independent))$coefficients
rownames(pid.interact) <- c("Intercept", "Treatment", "Democrat", "Independent", "Democrat x Treat", "Independent X Treat")
colnames(pid.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(pid.interact)
```


#### By Baseline Support
We analyze the data two ways. In Table S8, we present the conditional average treatment effect among individuals below the mean on the baseline support factor and above the mean on the trans.tolerance.dv.t1 factor. In Table S9, we present the interaction effect between a continuous variable for baseline support and the treatment indicator on the same factor, after having been residualized on the above specified covariates. We find no evidence of heterogeneous treatment effects. 

Note that the correlation between the baseline and the outcome is weak because we compute heterogenous treatment effects on a residualized version of the outcome.
**Table S8.**
```{r, eval=TRUE}
base.low <- data.frame(
  est.ate(data$trans.tolerance.dv.t1,
          data$scale_for_blocking_t0 < mean(data$scale_for_blocking_t0, na.rm = TRUE)))
base.high <- data.frame(
  est.ate(data$trans.tolerance.dv.t1,
          data$scale_for_blocking_t0 >= mean(data$scale_for_blocking_t0, na.rm = TRUE)))
base <- cbind(base.low, base.high)
colnames(base) <- c("Low Baseline", "High Baseline")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Baseline, separately. Linear regression with clustered standard errors.")
pander(t(base))
```


**Table S9.**
```{r, eval=TRUE}
baseline.interact <- summary(lm(t1$t1.resid ~ t1$treat_ind * t1$scale_for_blocking_t0))$coefficients
rownames(baseline.interact) <- c("Intercept", "Treat", "Democrat", "Baseline X Treat")
colnames(baseline.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Baseline, Interaction Term. Linear regression with clustered standard errors.")
pander(baseline.interact)
```

**Table S9b.**
```{r, eval=TRUE}
baseline.interact <- summary(lm(t1$trans.tolerance.dv.t1 ~ t1$treat_ind * t1$scale_for_blocking_t0))$coefficients
rownames(baseline.interact) <- c("Intercept", "Treat", "Democrat", "Baseline X Treat")
colnames(baseline.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Baseline, Interaction Term. Linear regression with clustered standard errors.")
pander(baseline.interact)
```

#### By Need for Cognition

We analyze the data two ways. In Table S10, we present the conditional average treatment effect among individuals below the mean on the Need for Cognition factor and above the mean on the trans.tolerance.dv.t1 factor. In Table S11, we present the interaction effect between a continuous variable for Need for Cognition and the treatment indicator on the same factor, after having been residualized on the above specified covariates. We find no evidence of heterogeneous treatment effects.

Recall that the Need for Cognition item was only asked on the third post-treatment survey, not the baseline survey. This means additional caution is warranted because the item was asked post-treatment; it is also not available for individuals who did not complete the t3 survey.


**Table S10.**
```{r, eval=TRUE, echo=TRUE}
nfc.low <- data.frame(
  est.ate(data$trans.tolerance.dv.t1, data$nfc_t3 < mean(data$nfc_t3, na.rm = TRUE)))
nfc.high <- data.frame(
  est.ate(data$trans.tolerance.dv.t1, data$nfc_t3 >= mean(data$nfc_t3, na.rm = TRUE)))
nfc <- cbind(nfc.low, nfc.high)
colnames(nfc) <- c("Low NFC", "High NFC")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Need for Cognition, separately. Linear regression with clustered standard errors.")
pander(t(nfc))
```


**Table S11.**
```{r, eval=TRUE, echo=TRUE}
nfc.interact <- summary(lm(t1$t1.resid ~ t1$treat_ind * t1$nfc_t3))$coefficients
rownames(nfc.interact) <- c("Intercept", "Treat", "NFC", "NFCxTreat")
colnames(nfc.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
set.caption("Effects at 3 Days by Need for Cognition, Interaction Term. Linear regression with clustered standard errors.")
panderOptions('table.caption.prefix','')
panderOptions('digits','2')
pander(nfc.interact)
```



#### Same sex marriage support  --- adding 


**Table S12.**
```{r, eval=TRUE, echo=TRUE}
ssm.low <- data.frame(
  est.ate(data$trans.tolerance.dv.t1, data$ssm_t0 < mean(data$ssm_t0, na.rm = TRUE)))
ssm.high <- data.frame(
  est.ate(data$trans.tolerance.dv.t1, data$ssm_t0 >= mean(data$ssm_t0, na.rm = TRUE)))
ssm <- cbind(ssm.low, ssm.high)
colnames(ssm) <- c("Low SSM", "High SSM")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Same Sex Marriage support, separately. Linear regression with clustered standard errors.")
pander(t(ssm))
```


**Table S13a.**
```{r, eval=TRUE}
ssm.interact <- summary(lm(t1$t1.resid ~ t1$treat_ind * t1$ssm_t0))$coefficients
rownames(ssm.interact) <- c("Intercept", "Treatment", "SSM", "SSM x Treat")
colnames(ssm.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(ssm.interact)
```


**Table S13b.**
```{r, eval=TRUE}
ssm.interact <- summary(lm(t1$trans.tolerance.dv.t1 ~ t1$treat_ind * t1$ssm_t0))$coefficients
rownames(ssm.interact) <- c("Intercept", "Treatment", "SSM", "SSM x Treat")
colnames(ssm.interact) <- c("Estimate", "Std. Error", "*t*", "*p*")
panderOptions('table.caption.prefix','')
set.caption("Effects at 3 Days by Party Registration, Interaction Term. Linear regression with clustered standard errors.")
pander(ssm.interact)
```

#### Machine Learning Algorithm for Other Subgroups

There are many other covariates available from the voter file and on our survey. In order to avoid a post hoc hypothesis testing exercise that would likely lead us to find at least one such covariate to predict the treatment effect purely by chance, we also implemented a machine learning procedure designed to automatically search for the existence of any robust heterogenous treatment effects (*44*). The procedure relies on the Lasso, a variable selection algorithm. The results return only the intercept, indicating that none of the covariates predict the treatment effect robustly; the treatment is broadly effective among subgroups. We take this result as propitious for the generalizability of the findings.

```{r}
# Residualize the dependent variable, then transform it per (*44*).
t1.resid <- summary(lm(data$trans.tolerance.dv.t1 ~ x))$residuals
data$t1.resid[as.numeric(names(t1.resid))] <- t1.resid # Maps residuals back into data.
data$transformed.outcome <- with(data, t1.resid * (treat_ind - .5) / .25)

# Vectors describing rows where the outcome was observed.
include.obs <- !is.na(data$transformed.outcome)
x.subset <- cbind(data$treat_ind[include.obs], x[include.obs,])
transformed.outcome <- data$transformed.outcome[include.obs]

# Lasso.
cvfit.lasso <- cv.glmnet(x.subset, transformed.outcome, alpha = 1)
coef(cvfit.lasso, s = "lambda.min")
```



## Further Explanation of and Replication Code for Results in Main Text

### Results In Main Text

* "After the intervention, the treatment group was considerably more accepting of transgender people than the placebo group (t = 4.03; p < 0.001)."
```{r}
est.ate(data$trans.tolerance.dv.t1)
```


* "These effects are substantively large: these brief conversations increased positivity towards transgender people on a feeling thermometer (20, 21) by approximately 10 points, an amount larger than the secular increase in positive affect towards gay men and lesbians among Americans between 1998 and 2012 (8.5 points; see table S22)."

```{r}
est.ate(data$therm_trans_t1)
```



```{r, results="asis", include=TRUE, message=FALSE, echo=TRUE, eval=TRUE}

df_dummy_trans <- t1_only_dummified
colnames(df_dummy_trans)[65] <- "vf_party_Other_Party"
colnames(df_dummy_trans)[66] <- "vf_racename_African_American"
df_split_trans <- modelr::resample_partition(df_dummy_trans, c(train=0.5, estim=0.5))
df_train_trans <- dplyr::as_tibble(df_split_trans$train)
df_est_trans<- dplyr::as_tibble(df_split_trans$estim)

other_dummies_trans <- purrr::keep(colnames(df_dummy_trans), ~. != "treat_ind")
contexts <- c("vf_age","vf_female", "vf_black", "vf_white", "vf_hispanic",
              "vf_vg_14", "vf_vg_12","vf_vg_10",
              "vf_democrat","vf_republican",
              "ssm_t0","ideology_t0","religious_t0",
              "exposure_gay_t0", "exposure_trans_t0",
              "pid_t0","scale_for_blocking_t0",
              "vf_independent", "vf_party_D", "vf_party_N" , "vf_party_R", "vf_party_Other_Party",
              "vf_racename_African_American", "vf_racename_Caucasian", "vf_racename_Hispanic", "vf_racename_Asian")

outcome <- "trans.tolerance.dv.t1"
treatment <- "treat_ind"
```


## Summarize context variables

```{r, results="asis", message=FALSE, echo=FALSE}
summarize_contexts(df_dummy_trans[c(outcome, contexts)])
```

## X-learners

```{r}
cates <- map("treat_ind", function(level) {
  other_dummies_trans <- purrr::keep(colnames(df_dummy_trans), ~. != "treat_ind")
  other_dummies_trans <- purrr::keep(other_dummies_trans, ~. != "trans.tolerance.dv.t1")
  
  level <- "treat_ind"
  outcome <- "trans.tolerance.dv.t1"
  
  X_train <- as.data.frame(df_train_trans[other_dummies_trans])
  W_train <- pull(df_train_trans, level)
  Y_train <- pull(df_train_trans, outcome)
  X_test <-  as.data.frame(df_est_trans[other_dummies_trans])
  xls <- hte::X_RF(feat = X_train,
                   tr = W_train,
                   yobs = Y_train,
                   ntree_first = 500,
                   ntree_second = 500,
                   ntree_prop = 500,
                   nthread = 1,
                   min_node_size_spl_first = 1,
                   min_node_size_ave_first = 1,
                   min_node_size_spl_second = 1,
                   min_node_size_ave_second = 1,
                   min_node_size_spl_prop = 1, 
                   min_node_size_ave_prop = 1)
  
  cate <- hte::EstimateCate(xls, X_test) %>% as_tibble() %>% rename(cate=value)
  
  data_with_cate <- bind_cols(df_est_trans, cate)

})

names(cates) <- "treat_ind"

```



```{r, results="asis", message=FALSE, eval=TRUE}
# Prints html table
walk2(cates, names(cates), function(data_with_cate, title) {
    # overall title
  Leaf_title <- str_c("\n<h4> ", title," </h4>\n")
  cat(Leaf_title)
  
  # Computes the ntiles of the "cate" column
  data_with_ntiles <- add_ntiles(data_with_cate, ntiles=5)
  
  # Multiple hyp. testing for context means given factor(ntiles). Keeps if at least 1 significant
  significant_contexts <- keep(contexts, ~has_significant(data_with_ntiles, ., "cate_ntile"))
  
  # Creates a table based on tile
  tab <- summarize_by_prediction_ntile(data=data_with_ntiles,
                                       covariates=significant_contexts,
                                       ntiles=5)
  
  # Prettyprint with HTML+Boostrap
  html <- pretty_table(tab, digits=2, title=title, prefix="Q")
  
  cat(html)
  
})
```


Significant contexts:

- gender_norm_looks_t0: To keep children from being confused, it’s better when men look and act like men, and women look and act like women.
- gender_norms_moral_t0: It is morally wrong for a man to present himself as a woman in public
- ssm_t0: same sex marriage support
- ideology_t0: political ideology
- therm_obama_t0: Obama feeling therm
- therm_gay_t0: gay men feeling therm
- therm_trans_t0: Feeling thermometer towards trans people
- scale_for_blocking_t0: factor used for blocking


